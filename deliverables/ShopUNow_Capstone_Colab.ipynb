{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ShopUNow AI Assistant - Agentic RAG Capstone Project\n",
        "\n",
        "> **Intelligent AI Assistant for Retail Customer & Employee Support**\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This notebook demonstrates an **Agentic RAG (Retrieval-Augmented Generation) system** built for ShopUNow, a fictional retail company. The assistant intelligently routes and answers queries from both **internal employees** and **external customers** across multiple departments.\n",
        "\n",
        "### Key Features\n",
        "\n",
        "| Feature | Implementation |\n",
        "|---------|---------------|\n",
        "| 4+ Departments | HR, IT Support, Billing, Shipping |\n",
        "| 10-15 QA pairs/dept | 15 per department (60 total) |\n",
        "| Sentiment Analysis | LLM-based ClassificationPipeline |\n",
        "| Department Routing | QueryRouter with rules |\n",
        "| RAG Pipeline | ChromaDB + DynamicKRetriever |\n",
        "| Human Escalation | Negative/Unknown triggers |\n",
        "| Stretch Goal | FastAPI REST API deployment |\n",
        "\n",
        "### Departments\n",
        "\n",
        "| Department | User Type | Description |\n",
        "|------------|-----------|-------------|\n",
        "| **Human Resources** | Internal Employee | PTO, payroll, benefits, policies |\n",
        "| **IT Support** | Internal Employee | Passwords, VPN, hardware, software |\n",
        "| **Billing & Payments** | External Customer | Refunds, invoices, payment methods |\n",
        "| **Shipping & Delivery** | External Customer | Order tracking, returns, delays |\n",
        "\n",
        "---\n",
        "\n",
        "**Author:** Mohsin  \n",
        "**Program:** Analytics Vidhya GenAI Pinnacle Program"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, we'll clone the repository and install dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/crowbarmassage/agentic-rag-assistant.git\n",
        "%cd agentic-rag-assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up API key (using Colab secrets or manual input)\n",
        "import os\n",
        "\n",
        "# Try to get from Colab secrets first\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "    print(\"API key loaded from Colab secrets\")\n",
        "except:\n",
        "    # Fall back to manual input\n",
        "    from getpass import getpass\n",
        "    os.environ['OPENAI_API_KEY'] = getpass('Enter your OpenAI API key: ')\n",
        "    print(\"API key set manually\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Architecture Overview\n",
        "\n",
        "The system follows this flow:\n",
        "\n",
        "```\n",
        "User Query\n",
        "    |\n",
        "    v\n",
        "+-------------------+\n",
        "| Classification    |  <- Sentiment + Department detection\n",
        "+-------------------+\n",
        "    |\n",
        "    v\n",
        "+-------------------+\n",
        "|     Router        |  <- Decides: RAG or Escalation?\n",
        "+-------------------+\n",
        "    |           |\n",
        "    v           v\n",
        "+-------+   +------------+\n",
        "|  RAG  |   | Escalation |\n",
        "+-------+   +------------+\n",
        "    |\n",
        "    v\n",
        "+-------------------+\n",
        "| Response + Sources|\n",
        "+-------------------+\n",
        "```\n",
        "\n",
        "### Components\n",
        "\n",
        "1. **ClassificationPipeline**: Uses LLM to detect sentiment and classify department\n",
        "2. **QueryRouter**: Rules-based routing (negative sentiment or unknown dept -> escalate)\n",
        "3. **DynamicKRetriever**: ChromaDB vector search with adaptive result count\n",
        "4. **ResponseGenerator**: LLM generates answer from retrieved context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Generation\n",
        "\n",
        "Generate synthetic FAQ data for all 4 departments using LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate FAQ data (15 QA pairs per department)\n",
        "!python datagen/generate_faqs_standalone.py --num-pairs 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify generated data\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "data_dir = Path('./data/raw')\n",
        "total_pairs = 0\n",
        "\n",
        "print(\"Generated FAQ Data Summary\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for file in sorted(data_dir.glob('*.json')):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "    count = len(data.get('qa_pairs', []))\n",
        "    total_pairs += count\n",
        "    print(f\"{data['department_name']:25} | {count:2} QA pairs | {data['user_type']}\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"Total: {total_pairs} QA pairs across 4 departments\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show sample QA pair from each department\n",
        "print(\"\\nSample QA Pairs\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for file in sorted(data_dir.glob('*.json')):\n",
        "    with open(file) as f:\n",
        "        data = json.load(f)\n",
        "    qa = data['qa_pairs'][0]\n",
        "    print(f\"\\n[{data['department'].upper()}]\")\n",
        "    print(f\"Q: {qa['question']}\")\n",
        "    print(f\"A: {qa['answer'][:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Vector Store Ingestion\n",
        "\n",
        "Ingest FAQ data into ChromaDB with embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ingest data into ChromaDB\n",
        "from src.vectorstore import ingest_faqs\n",
        "\n",
        "ingest_faqs(\n",
        "    data_dir='./data/raw',\n",
        "    chroma_dir='./data/chroma_db',\n",
        "    reset_collection=True\n",
        ")\n",
        "\n",
        "print(\"\\nData ingestion complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify ChromaDB contents\n",
        "from src.vectorstore import ChromaDBClient\n",
        "from src.providers import EmbeddingProviderFactory\n",
        "from src.models import Department\n",
        "\n",
        "embedder = EmbeddingProviderFactory.create('sentence_transformers')\n",
        "chroma = ChromaDBClient('./data/chroma_db', embedder)\n",
        "\n",
        "print(\"ChromaDB Document Counts\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total documents: {chroma.get_document_count()}\")\n",
        "print(f\"  HR:          {chroma.get_document_count(Department.HR)}\")\n",
        "print(f\"  IT Support:  {chroma.get_document_count(Department.IT_SUPPORT)}\")\n",
        "print(f\"  Billing:     {chroma.get_document_count(Department.BILLING)}\")\n",
        "print(f\"  Shipping:    {chroma.get_document_count(Department.SHIPPING)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Initialize the Orchestrator\n",
        "\n",
        "The ShopUNowOrchestrator coordinates all pipeline components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.orchestrator import ShopUNowOrchestrator\n",
        "from src.config import Settings\n",
        "\n",
        "# Initialize with settings\n",
        "settings = Settings(\n",
        "    llm_provider='openai',\n",
        "    llm_model='gpt-4o-mini',\n",
        "    embedding_provider='sentence_transformers',\n",
        "    embedding_model='all-MiniLM-L6-v2',\n",
        "    retrieval_min_threshold=0.3,\n",
        "    retrieval_max_k=10\n",
        ")\n",
        "\n",
        "orchestrator = ShopUNowOrchestrator(settings)\n",
        "\n",
        "print(\"Orchestrator initialized!\")\n",
        "print(f\"  LLM: {orchestrator.llm.provider_name}\")\n",
        "print(f\"  Embeddings: {orchestrator.embedding.provider_name} (dim={orchestrator.embedding.dimension})\")\n",
        "print(f\"  Documents: {orchestrator.chroma.get_document_count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Demo: Query Processing\n",
        "\n",
        "Now let's demonstrate the system with sample queries across all departments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.models import QueryRequest, QueryResponse, EscalationResponse\n",
        "\n",
        "def demo_query(query_text: str):\n",
        "    \"\"\"Process a query and display the result.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"QUERY: {query_text}\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    request = QueryRequest(query=query_text)\n",
        "    response = orchestrator.process_query(request)\n",
        "    \n",
        "    if isinstance(response, EscalationResponse):\n",
        "        print(f\"\\n>>> ESCALATED TO HUMAN AGENT <<<\")\n",
        "        print(f\"Reason: {response.reason}\")\n",
        "        print(f\"Ticket ID: {response.ticket_id}\")\n",
        "        print(f\"Message: {response.message}\")\n",
        "    else:\n",
        "        print(f\"\\nDepartment: {response.department.value.upper()}\")\n",
        "        print(f\"Sentiment: {response.sentiment.value}\")\n",
        "        print(f\"Confidence: {response.confidence:.2f}\")\n",
        "        print(f\"\\nANSWER: {response.answer}\")\n",
        "        print(f\"\\nSources ({len(response.sources)}):\")\n",
        "        for src in response.sources[:3]:\n",
        "            print(f\"  - [{src.relevance_score:.2f}] {src.question_matched[:60]}...\")\n",
        "        print(f\"\\nProcessing time: {response.processing_time_ms:.0f}ms\")\n",
        "    \n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 HR Department (Internal Employee)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# HR Query - Neutral sentiment -> RAG response\n",
        "response = demo_query(\"How do I apply for paid time off?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 IT Support Department (Internal Employee)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# IT Support Query - Neutral sentiment -> RAG response\n",
        "response = demo_query(\"I forgot my password and can't login to my computer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Billing Department (External Customer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Billing Query - Neutral sentiment -> RAG response\n",
        "response = demo_query(\"How can I request a refund for my recent purchase?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4 Shipping Department (External Customer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shipping Query - Neutral sentiment -> RAG response\n",
        "response = demo_query(\"Where is my order? I placed it last week.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.5 Negative Sentiment -> Human Escalation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Negative sentiment -> Escalation\n",
        "response = demo_query(\"This is absolutely ridiculous! I've been waiting for 3 weeks and nobody can help me!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.6 Unknown Department -> Human Escalation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Unknown department -> Escalation\n",
        "response = demo_query(\"What's the weather like today?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.7 Positive Sentiment -> RAG Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Positive sentiment with question -> RAG response (not escalated)\n",
        "response = demo_query(\"Thanks so much for your help! Quick question - how do I update my payment method?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Component Deep Dive\n",
        "\n",
        "Let's examine each component in detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Classification Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.pipelines.classification import ClassificationPipeline\n",
        "\n",
        "classifier = ClassificationPipeline(orchestrator.llm)\n",
        "\n",
        "# Test sentiment detection\n",
        "test_queries = [\n",
        "    \"How do I check my PTO balance?\",\n",
        "    \"Thank you so much for your help!\",\n",
        "    \"This is unacceptable! I demand a refund NOW!\"\n",
        "]\n",
        "\n",
        "print(\"Sentiment Analysis Results\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for query in test_queries:\n",
        "    result = classifier.detect_sentiment(query)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    print(f\"  Sentiment: {result.sentiment.value}\")\n",
        "    print(f\"  Confidence: {result.confidence:.2f}\")\n",
        "    print(f\"  Indicators: {result.indicators}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test department classification\n",
        "test_queries = [\n",
        "    \"I need to apply for vacation days\",\n",
        "    \"My laptop won't turn on\",\n",
        "    \"I was charged twice for the same order\",\n",
        "    \"When will my package arrive?\"\n",
        "]\n",
        "\n",
        "print(\"Department Classification Results\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for query in test_queries:\n",
        "    result = classifier.classify_department(query)\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    print(f\"  Department: {result.department.value}\")\n",
        "    print(f\"  User Type: {result.user_type.value}\")\n",
        "    print(f\"  Confidence: {result.confidence:.2f}\")\n",
        "    print(f\"  Reasoning: {result.reasoning}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Query Router"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.routing import QueryRouter\n",
        "from src.models import ClassificationResult, Sentiment, Department, UserType, RouteDecision\n",
        "\n",
        "router = QueryRouter()\n",
        "\n",
        "# Test routing decisions\n",
        "test_cases = [\n",
        "    (\"Neutral + Valid Dept\", Sentiment.NEUTRAL, Department.HR),\n",
        "    (\"Positive + Valid Dept\", Sentiment.POSITIVE, Department.BILLING),\n",
        "    (\"Negative + Valid Dept\", Sentiment.NEGATIVE, Department.SHIPPING),\n",
        "    (\"Neutral + Unknown Dept\", Sentiment.NEUTRAL, Department.UNKNOWN),\n",
        "]\n",
        "\n",
        "print(\"Routing Decision Matrix\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Scenario':25} | {'Sentiment':10} | {'Department':12} | {'Route':20}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for name, sentiment, dept in test_cases:\n",
        "    classification = ClassificationResult(\n",
        "        sentiment=sentiment,\n",
        "        department=dept,\n",
        "        user_type=UserType.UNKNOWN,\n",
        "        confidence=0.9,\n",
        "        reasoning=\"test\"\n",
        "    )\n",
        "    decision = router.route(classification)\n",
        "    route = \"ESCALATE\" if decision.should_escalate else \"RAG\"\n",
        "    print(f\"{name:25} | {sentiment.value:10} | {dept.value:12} | {route:20}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 RAG Retrieval Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.pipelines.retrieval import DynamicKRetriever\n",
        "\n",
        "retriever = DynamicKRetriever(\n",
        "    chroma_client=orchestrator.chroma,\n",
        "    min_threshold=0.3,\n",
        "    max_k=10,\n",
        "    drop_off_ratio=0.7\n",
        ")\n",
        "\n",
        "# Test retrieval\n",
        "result = retriever.retrieve(\n",
        "    query=\"How do I request time off for vacation?\",\n",
        "    department=Department.HR\n",
        ")\n",
        "\n",
        "print(\"RAG Retrieval Results\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Query: {result.query}\")\n",
        "print(f\"Department Filter: {result.department_filter.value}\")\n",
        "print(f\"Documents Retrieved: {result.retrieval_count}\")\n",
        "print(f\"Threshold Used: {result.threshold_used}\")\n",
        "print(f\"\\nTop Results:\")\n",
        "\n",
        "for doc in result.documents[:5]:\n",
        "    print(f\"\\n  [{doc.similarity_score:.3f}] {doc.id}\")\n",
        "    print(f\"  Q: {doc.question[:70]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. API Deployment (Stretch Goal)\n",
        "\n",
        "The system includes a FastAPI REST API for production deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show the API endpoints\n",
        "print(\"FastAPI Endpoints\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\"\"\n",
        "POST /query          - Process user query\n",
        "GET  /health         - Health check\n",
        "GET  /health?deep=true - Deep health check (all components)\n",
        "GET  /departments    - List available departments\n",
        "GET  /docs           - Swagger UI documentation\n",
        "GET  /redoc          - ReDoc documentation\n",
        "\"\"\")\n",
        "\n",
        "# Example curl commands\n",
        "print(\"\\nExample API Usage:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"\"\"\n",
        "# Start the API\n",
        "python run.py\n",
        "\n",
        "# Query the assistant\n",
        "curl -X POST http://localhost:8000/query \\\\\n",
        "  -H \"Content-Type: application/json\" \\\\\n",
        "  -d '{\"query\": \"How do I apply for PTO?\"}'\n",
        "\n",
        "# Health check\n",
        "curl http://localhost:8000/health?deep=true\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary\n",
        "\n",
        "### Requirements Checklist\n",
        "\n",
        "| Requirement | Status | Implementation |\n",
        "|-------------|--------|---------------|\n",
        "| 4+ departments (2 internal, 2 external) | ✅ | HR, IT Support (internal) + Billing, Shipping (external) |\n",
        "| 10-15 QA pairs per department | ✅ | 15 per department = 60 total |\n",
        "| Sentiment analysis | ✅ | LLM-based ClassificationPipeline |\n",
        "| Department routing | ✅ | QueryRouter with rules |\n",
        "| RAG pipeline | ✅ | ChromaDB + DynamicKRetriever + LLM generation |\n",
        "| Human escalation | ✅ | Negative sentiment or unknown department |\n",
        "| 1+ stretch goal | ✅ | FastAPI REST API deployment |\n",
        "\n",
        "### Architecture Highlights\n",
        "\n",
        "1. **Provider Abstraction**: Easily swap LLM (OpenAI/Gemini/Groq) and embedding providers\n",
        "2. **Dynamic K Retrieval**: Adaptive result count based on relevance scores\n",
        "3. **Metadata Filtering**: Department-specific vector search in ChromaDB\n",
        "4. **Source Attribution**: Transparent citations for every response\n",
        "5. **Production Ready**: FastAPI with health checks and CORS support\n",
        "\n",
        "### Key Files\n",
        "\n",
        "| File | Purpose |\n",
        "|------|--------|\n",
        "| `src/orchestrator.py` | Main pipeline coordinator |\n",
        "| `src/pipelines/classification.py` | Sentiment + department detection |\n",
        "| `src/pipelines/retrieval.py` | Dynamic K retrieval logic |\n",
        "| `src/routing/router.py` | Escalation decision logic |\n",
        "| `src/vectorstore/chroma_client.py` | ChromaDB wrapper |\n",
        "| `src/main.py` | FastAPI application |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"   ShopUNow AI Assistant - Capstone Project Complete!\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nThank you for reviewing this project.\")\n",
        "print(\"\\nFor more details, see:\")\n",
        "print(\"  - README.md: Project overview and setup\")\n",
        "print(\"  - TECH_SPECS.md: Detailed technical documentation\")\n",
        "print(\"  - deliverables/ARCHITECTURE_REPORT.md: Architecture deep-dive\")"
      ]
    }
  ]
}
